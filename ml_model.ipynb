{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Step 1: Load the data\n",
        "df = pd.read_csv('/content/glofdatabase_V3-1.csv', encoding='latin-1')\n",
        "df = df.drop(index=0)  # Drop first metadata row\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Step 2: Select important columns for glacier outburst analysis\n",
        "new_df = df[['Glacier', 'RGI_Glacier_Id', 'RGI_Glacier_Area', 'Lake_type',\n",
        "             'Lake_area_before', 'Mean_Lake_Volume_VL', 'Mean_Flood_Volume_V0',\n",
        "             'Peak_discharge_Qp', 'Mechanism', 'River', 'Impact_and_destruction']]\n",
        "\n",
        "numerical_cols = ['RGI_Glacier_Area', 'Lake_area_before',\n",
        "                  'Mean_Lake_Volume_VL', 'Mean_Flood_Volume_V0',\n",
        "                  'Peak_discharge_Qp', 'Impact_and_destruction']"
      ],
      "metadata": {
        "id": "OgnmjSOpg_A4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_numeric_column(series):\n",
        "    return pd.to_numeric(series.astype(str).str.extract(r'([\\d\\.\\-eE]+)')[0], errors='coerce')\n",
        "\n",
        "for col in numerical_cols:\n",
        "    new_df[col] = clean_numeric_column(new_df[col])"
      ],
      "metadata": {
        "id": "qlxLbqY9g_cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "new_df[numerical_cols] = knn_imputer.fit_transform(new_df[numerical_cols])"
      ],
      "metadata": {
        "id": "YqSlA-NzhBIA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Fill missing categorical data with 'Unknown'\n",
        "categorical_cols = ['Glacier', 'RGI_Glacier_Id', 'Lake_type', 'Mechanism', 'River']\n",
        "new_df[categorical_cols] = new_df[categorical_cols].fillna('Unknown')"
      ],
      "metadata": {
        "id": "0d_HCULchDdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 7: Check final cleaned dataset\n",
        "print(new_df.head())\n",
        "print(\"\\nMissing values:\\n\", new_df.isnull().sum())"
      ],
      "metadata": {
        "id": "fjQNLUDbhE1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.head(5)"
      ],
      "metadata": {
        "id": "UNWdu0L0hGki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold_discharge = 5000  # in m³/s\n",
        "threshold_flood_volume = 100000000  # in m³\n",
        "\n",
        "# Filter risky rivers\n",
        "risky_rivers = new_df[\n",
        "    (new_df['Peak_discharge_Qp'] > threshold_discharge) |\n",
        "    (new_df['Mean_Flood_Volume_V0'] > threshold_flood_volume)\n",
        "]"
      ],
      "metadata": {
        "id": "xXqOqQW3hLDA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show result\n",
        "print(\"Filtered Risky Rivers (Potential Overflow):\")\n",
        "print(risky_rivers[['River', 'Peak_discharge_Qp', 'Mean_Flood_Volume_V0']])\n",
        "\n",
        "# Optional: Save to CSV\n",
        "risky_rivers.to_csv(\"risky_rivers.csv\", index=False)"
      ],
      "metadata": {
        "id": "UCTe3gewhtYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    new_df[col] = le.fit_transform(new_df[col])\n",
        "    label_encoders[col] = le\n"
      ],
      "metadata": {
        "id": "18yflsfLhu1n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c75039-67f4-4af8-f21a-79d1dd358d49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-4dedc7df4a00>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df[col] = le.fit_transform(new_df[col])\n",
            "<ipython-input-11-4dedc7df4a00>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df[col] = le.fit_transform(new_df[col])\n",
            "<ipython-input-11-4dedc7df4a00>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df[col] = le.fit_transform(new_df[col])\n",
            "<ipython-input-11-4dedc7df4a00>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df[col] = le.fit_transform(new_df[col])\n",
            "<ipython-input-11-4dedc7df4a00>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df[col] = le.fit_transform(new_df[col])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target: 1 if high risk, else 0\n",
        "new_df['High_Risk'] = ((new_df['Peak_discharge_Qp'] > threshold_discharge) |\n",
        "                       (new_df['Mean_Flood_Volume_V0'] > threshold_flood_volume)).astype(int)\n",
        "\n",
        "# Features and target\n",
        "X = new_df.drop(columns=['High_Risk'])\n",
        "y = new_df['High_Risk']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRgpckXktBy-",
        "outputId": "66d7007e-f473-4f8a-9f91-e5a598c8eb1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-bfc90aec60da>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df['High_Risk'] = ((new_df['Peak_discharge_Qp'] > threshold_discharge) |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "N5FVvDcPtCLD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "models = {\n",
        "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
        "    \"LogisticRegression\": LogisticRegression(),\n",
        "    \"SVM\": SVC()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    print(f\"\\n{name} Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtVbHryptDzd",
        "outputId": "5ad4adf8-3c6c-4811-f4c4-1d532e28a7b7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RandomForest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        21\n",
            "           1       1.00      1.00      1.00        47\n",
            "\n",
            "    accuracy                           1.00        68\n",
            "   macro avg       1.00      1.00      1.00        68\n",
            "weighted avg       1.00      1.00      1.00        68\n",
            "\n",
            "Accuracy: 1.00\n",
            "\n",
            "LogisticRegression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        21\n",
            "           1       1.00      1.00      1.00        47\n",
            "\n",
            "    accuracy                           1.00        68\n",
            "   macro avg       1.00      1.00      1.00        68\n",
            "weighted avg       1.00      1.00      1.00        68\n",
            "\n",
            "Accuracy: 1.00\n",
            "\n",
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98        21\n",
            "           1       1.00      0.98      0.99        47\n",
            "\n",
            "    accuracy                           0.99        68\n",
            "   macro avg       0.98      0.99      0.98        68\n",
            "weighted avg       0.99      0.99      0.99        68\n",
            "\n",
            "Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "best_model = RandomForestClassifier(random_state=42)\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save model and scaler\n",
        "joblib.dump(best_model, 'glacier_risk_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "joblib.dump(label_encoders, 'label_encoders.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tpb_QA5stFf-",
        "outputId": "c3f59108-4e68-499f-a6dd-3893e50b054a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoders.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VDvBrHDitNkL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}